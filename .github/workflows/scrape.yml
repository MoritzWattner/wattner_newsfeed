name: DE-Plan Feed Watcher

on:
  # Effiziente Schedules für verschiedene Prioritäten
  schedule:
    - cron: "*/30 * * * *"    # Alle 30 Min - Fast updates (News/Test sites)
    - cron: "0 */4 * * *"     # Alle 4 Std - Normal updates (Verwaltungsseiten) 
    - cron: "0 9 * * *"       # Täglich 9 Uhr - Slow updates (sehr statische Sites)
  
  # Manueller Trigger
  workflow_dispatch:
    inputs:
      update_type:
        description: 'Update type to run'
        required: true
        default: 'normal'
        type: choice
        options:
        - fast
        - normal 
        - slow
        - all

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: feed-scraper-${{ github.event.schedule || inputs.update_type || 'manual' }}
  cancel-in-progress: true

jobs:
  determine-sites:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      update_type: ${{ steps.check.outputs.update_type }}
    steps:
      - name: Determine update type
        id: check
        run: |
          # Bestimme Update-Typ basierend auf Trigger
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "update_type=${{ inputs.update_type }}" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event.schedule }}" == "*/30 * * * *" ]]; then
            # Fast updates nur zu Geschäftszeiten (UTC)
            hour=$(date -u +%H)
            if [[ $hour -ge 6 && $hour -le 18 ]]; then
              echo "update_type=fast" >> $GITHUB_OUTPUT
              echo "should_run=true" >> $GITHUB_OUTPUT
            else
              echo "should_run=false" >> $GITHUB_OUTPUT
            fi
          elif [[ "${{ github.event.schedule }}" == "0 */4 * * *" ]]; then
            echo "update_type=normal" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event.schedule }}" == "0 9 * * *" ]]; then
            echo "update_type=slow" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
          else
            echo "update_type=normal" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
          fi

  scrape:
    needs: determine-sites
    if: needs.determine-sites.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: requirements.txt
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # System tools für XML validation und JSON processing
          sudo apt-get update && sudo apt-get install -y jq libxml2-utils
          
      - name: Show current state
        run: |
          echo "=== WORKFLOW INFO ==="
          echo "Update type: ${{ needs.determine-sites.outputs.update_type }}"
          echo "Trigger: ${{ github.event_name }}"
          echo "Schedule: ${{ github.event.schedule }}"
          echo "Time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          
          echo "=== WORKSPACE ==="
          ls -la
          
          echo "=== CURRENT STATE ==="
          if [ -f data/state.json ]; then
            echo "State file size: $(wc -c < data/state.json) bytes"
            echo "Sites tracked: $(jq -r '.sites | length' data/state.json 2>/dev/null || echo 'N/A')"
            echo "Total items: $(jq -r '.items | length' data/state.json 2>/dev/null || echo 'N/A')"
            echo "Last save: $(jq -r '.metadata.last_save // "Unknown"' data/state.json 2>/dev/null)"
          else
            echo "No state file found - fresh start"
          fi
          
      - name: Create filtered config
        run: |
          # Erstelle gefilterte Konfiguration basierend auf update_type
          UPDATE_TYPE="${{ needs.determine-sites.outputs.update_type }}"
          
          if [[ "$UPDATE_TYPE" == "all" ]]; then
            echo "Using full configuration (all sites)"
            cp config.yml config_filtered.yml
          else
            echo "Filtering config for update_type: $UPDATE_TYPE"
            python3 << 'EOF'
          import yaml
          import sys
          
          update_type = "${{ needs.determine-sites.outputs.update_type }}"
          
          with open('config.yml', 'r') as f:
              config = yaml.safe_load(f)
          
          # Filter sites by update_frequency
          if update_type != 'all':
              original_count = len(config.get('sites', []))
              filtered_sites = []
              
              for site in config.get('sites', []):
                  site_freq = site.get('update_frequency', 'normal')
                  if site_freq == update_type:
                      filtered_sites.append(site)
              
              config['sites'] = filtered_sites
              print(f"Filtered {original_count} sites to {len(filtered_sites)} for '{update_type}' updates")
          
          with open('config_filtered.yml', 'w') as f:
              yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
          EOF
          fi
          
          echo "Sites to process: $(yq eval '.sites | length' config_filtered.yml)"
          
      - name: Run scraper
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          set -euo pipefail
          
          echo "Starting scraper with filtered config..."
          python scraper.py --config config_filtered.yml --once
          
          # Validate results
          if [ ! -d "feeds" ] || [ -z "$(ls -A feeds 2>/dev/null)" ]; then
            echo "WARNING: No feeds generated!"
            # Don't fail - might be intentional if no changes
          else
            echo "Generated feeds: $(ls feeds | wc -l)"
          fi
          
      - name: Validate feeds
        run: |
          if [ -d "feeds" ] && [ -n "$(ls -A feeds)" ]; then
            echo "Validating RSS feeds..."
            VALID_FEEDS=0
            INVALID_FEEDS=0
            
            for feed in feeds/*.xml; do
              if xmllint --noout "$feed" 2>/dev/null; then
                VALID_FEEDS=$((VALID_FEEDS + 1))
              else
                echo "INVALID XML: $feed"
                echo "--- First 10 lines ---"
                head -10 "$feed"
                echo "--- Last 5 lines ---" 
                tail -5 "$feed"
                INVALID_FEEDS=$((INVALID_FEEDS + 1))
              fi
            done
            
            echo "Validation result: $VALID_FEEDS valid, $INVALID_FEEDS invalid feeds"
            
            if [ $INVALID_FEEDS -gt 0 ]; then
              echo "ERROR: Some feeds have invalid XML"
              exit 1
            fi
          else
            echo "No feeds to validate"
          fi
          
      - name: Show results
        run: |
          echo "=== SCRAPING RESULTS ==="
          
          if [ -f data/state.json ]; then
            echo "=== Updated State ==="
            echo "State file size: $(wc -c < data/state.json) bytes"
            echo "Sites: $(jq -r '.sites | length' data/state.json)"
            echo "Items: $(jq -r '.items | length' data/state.json)"
            
            echo ""
            echo "=== Recent Changes ==="
            jq -r '.items[-5:] | .[] | "\(.timestamp[:19]) | \(.name) | \(.change_type)"' data/state.json || echo "No recent items"
            
            echo ""
            echo "=== Sites by Bundesland ==="
            jq -r '.sites | group_by(.bundesland) | .[] | "\(.[0].bundesland): \(length) sites"' data/state.json || echo "No sites data"
          fi
          
          if [ -d feeds ]; then
            echo ""
            echo "=== Generated Feeds ==="
            ls -la feeds/ || echo "No feeds directory"
          fi
          
      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-${{ needs.determine-sites.outputs.update_type }}-${{ github.run_number }}
          path: |
            data/state.json
            config_filtered.yml
            feeds/*.xml
          if-no-files-found: warn
          retention-days: 7
          
      - name: Commit state changes
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Nur state.json committen wenn es Änderungen gibt
          if [ -f data/state.json ]; then
            git add data/state.json
            
            if git diff --staged --quiet; then
              echo "No state changes to commit"
            else
              CHANGES=$(git diff --staged --stat data/state.json | tail -1)
              git commit -m "Update state [${{ needs.determine-sites.outputs.update_type }}] - $(date -u '+%Y-%m-%d %H:%M UTC') [skip ci]

              $CHANGES"
              git push origin HEAD
              echo "State changes committed and pushed"
            fi
          else
            echo "ERROR: No state.json to commit!"
            exit 1
          fi
          
      - name: Setup Pages
        if: success()
        uses: actions/configure-pages@v5
        
      - name: Upload feeds to Pages
        if: success()
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./feeds
          
      - name: Deploy to GitHub Pages  
        if: success()
        id: deployment
        uses: actions/deploy-pages@v4

  # Health Check Job - läuft separat um Probleme zu erkennen
  health-check:
    needs: [determine-sites, scrape]
    if: always() && needs.determine-sites.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Check workflow health
        run: |
          echo "=== WORKFLOW HEALTH CHECK ==="
          echo "Update type: ${{ needs.determine-sites.outputs.update_type }}"
          echo "Scrape job status: ${{ needs.scrape.result }}"
          
          # Check if feeds are accessible
          if curl -f -s -I "https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/DE-deutschland.xml" > /dev/null; then
            echo "Deutschland feed accessible"
          else
            echo "Deutschland feed not accessible"
          fi
          
          # Basic statistics
          if [ -f data/state.json ]; then
            TOTAL_SITES=$(jq -r '.sites | length' data/state.json)
            RECENT_CHANGES=$(jq -r '[.items[] | select(.timestamp > (now - 86400 | strftime("%Y-%m-%dT%H:%M:%S")))] | length' data/state.json)
            echo "Total sites: $TOTAL_SITES"
            echo "Changes in last 24h: $RECENT_CHANGES"
          fi
          
          # Report success/failure
          if [[ "${{ needs.scrape.result }}" == "success" ]]; then
            echo "Workflow completed successfully"
          else
            echo "Workflow had issues - check logs"
            exit 1
          fi
